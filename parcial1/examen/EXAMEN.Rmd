---
title: "Examen Parcial 1"
author: "ByteMiners"
date: "23/02/2020"
output:
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Análisis exploratorio de datos
```{r, echo=TRUE,message=FALSE,warning=FALSE}
library(ggplot2)
library(cowplot)
library(dplyr)
library(grid)
library(FactoMineR)
library(factoextra)
library(corrplot)
```
# 1. Exploración y visualización de variables
## 1.1 Explorar la base de datos, realizar los cambios necesarios y convenientes para poder trabajar con ella.
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
df <- read.csv("Ejercicio 1.csv", sep = ",")

#Trasponer las columnas del df para que las características de cada observacion estén ordenadas por columnas 
df_transposed <- as.data.frame(t(as.matrix(df)))

# Eliminar observaciones con valores NA
df_transposed_omitted<-na.omit(df_transposed)

# Colocar nombre a las columnas y eliminar la primera fila 
names(df_transposed_omitted) <- c("Peso","Estatura","Edad","Complexión","Papás_separados","Cantidad_hermanos",
                                  "Trabaja", "Horas_trab_dia", "Horas_trab_mes", "Salario_mes")

updated_data <- df_transposed_omitted[-c(1),] 
```
# 2. Metodo de reducción de dimensión (PCA)
## 2.1 PCA base de datos PCA1
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
df2<-read.csv("Ejercicio 2.1.csv", sep = ",")
res.pca <- PCA(df2[,-1], graph = F)

eig.val <- get_eigenvalue(res.pca)
eig.val
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 90))

var <- get_pca_var(res.pca)

corrplot(var$cos2, is.corr=FALSE)

fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE # Avoid text overlapping
)

fviz_pca_var(res.pca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)

fviz_pca_ind(res.pca,
             geom.ind = "point", # show points only (nbut not "text")
             col.ind =df2$tipo, # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups")
```
## 2.2 PCA base de datos PCA2
```{r, echo=TRUE,tidy=TRUE}
url<-"http://web.stanford.edu/~hastie/ElemStatLearn//datasets/zip.digits/train.2"
data<-read.csv(url)

data.pca = scale(data)
data.pca <- prcomp(data, center = F, scale=T)
prop_varianza <- data.pca$sdev^2 / sum(data.pca$sdev^2)
prop_varianza_acum <- cumsum(prop_varianza)

ggplot(data = data.frame(prop_varianza, pc = 1:256),
       aes(x = pc, y = prop_varianza)) +
  xlim(0, 50) +
  geom_col(width = 0.3) +
  scale_y_continuous(limits = c(0,.5)) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. de varianza explicada")

ggplot(data = data.frame(prop_varianza_acum, pc = 1:256),
       aes(x = pc, y = prop_varianza_acum, group = 1)) +
  geom_point() +
  geom_line() +
  geom_label(aes(label = round(prop_varianza_acum,2))) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. varianza explicada acumulada")
```

# 4. Metodo de reducción de dimensión (CCA)