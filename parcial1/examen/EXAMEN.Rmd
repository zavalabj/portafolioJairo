---
title: "Examen Parcial 1"
author: "ByteMiners"
date: "23/02/2020"
output:
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Análisis exploratorio de datos
```{r, echo=TRUE,message=FALSE,warning=FALSE}
library(ggplot2)
library(cowplot)
library(dplyr)
library(grid)
library(FactoMineR)
library(factoextra)
library(corrplot)
```
# 1. Exploración y visualización de variables
## 1.1 Explorar la base de datos, realizar los cambios necesarios y convenientes para poder trabajar con ella.
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
df <- read.csv("Ejercicio 1.csv", sep = ",")

#Trasponer las columnas del df para que las características de cada observacion estén ordenadas por columnas 
df_transposed <- as.data.frame(t(as.matrix(df)))

# Eliminar observaciones con valores NA
df_transposed_omitted<-na.omit(df_transposed)

# Colocar nombre a las columnas y eliminar la primera fila 
names(df_transposed_omitted) <- c("Peso","Estatura","Edad","Complexión","Papas_separados","Cantidad_hermanos",
                                  "Trabaja", "Horas_trab_dia", "Horas_trab_mes", "Salario_mes")

updated_data <- df_transposed_omitted[-c(1),] 
```
## 1.2  Expliquen por medio de tablas esta información. En la tabla debe aparecer simultáneamente la frecuencia y el porcentaje
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
```

##1.3 Hagan un gráfico donde pueda explicar las variables dependientes.
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
```

## 1.4 Construyan diferentes gráficos donde puedan mostrar patrones y detalles de la base de datos con respecto a una nueva variable que podemos denominar: “categoría”
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}

# Número de personas por categoría
cantidad_personas <- c(sum(with(updated_data, as.numeric(Edad) < 18.0)), 
                       sum(with(updated_data, as.numeric(Edad)>=18.0 & as.numeric(Edad)<=25.0)),
                       sum(with(updated_data, as.numeric(Edad) > 25.0)))

dist_personas <- data.frame(Categoria=c("Junior", "Señor", "Mayor"), Cantidad=cantidad_personas)
ggplot(dist_personas, aes(x=Categoria, y=Cantidad)) + geom_bar(stat = "identity") + coord_flip() + labs(title="Distribución de personas por categoría")+
  geom_text(aes(y=Cantidad, label=cantidad_personas), vjust=1.5, color="white", size=3.5, hjust="right")

# Salario mensual promedio de una persona dependiendo su categoría
junior <- filter(updated_data, as.numeric(Edad) <18.0)
senior <- filter(updated_data, as.numeric(Edad)>=18.0 & as.numeric(Edad)<=25.0)
mayor <- filter(updated_data, as.numeric(Edad) > 25.0)

prom_jun <- mean(as.numeric(as.numeric_version(junior$Salario_mes)))
prom_sen <- mean(as.numeric(as.numeric_version(senior$Salario_mes)))
prom_may <- mean(as.numeric(as.numeric_version(mayor$Salario_mes)))

Salario <- c(format(round(prom_jun, 2), nsmall = 2), 
                      format(round(prom_sen, 2), nsmall = 2),
                      format(round(prom_may, 2), nsmall = 2))

salario_trab <- data.frame(Categoria=c("Junior", "Señor", "Mayor"), Salario_Promedio = Salario)

ggplot(horas_trab, aes(x=Categoria, y=Salario)) + geom_bar(stat = "identity") + coord_flip() + labs(title="Salario mensual promedio dependiendo la categoría")+
  geom_text(aes(y=Salario, label=Salario), vjust=1.5, color="white", size=3.5, hjust="right")

# Número de personas con padres separados por categoría
cantidad_personas <- c(sum(with(junior, Papas_separados == "SI")), 
                       sum(with(senior, Papas_separados == "SI")),
                       sum(with(mayor, Papas_separados == "SI")))

dist_personas <- data.frame(Categoria=c("Junior", "Señor", "Mayor"), Cantidad=cantidad_personas)
ggplot(dist_personas, aes(x=Categoria, y=Cantidad)) + geom_bar(stat = "identity") + coord_flip() + labs(title="Número de personas con padres separados por categoría")+
  geom_text(aes(y=Cantidad, label=cantidad_personas), vjust=1.5, color="white", size=3.5, hjust="right")

```
# 2. Metodo de reducción de dimensión (PCA)


## 2.1 PCA base de datos PCA1
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
df2<-read.csv("Ejercicio 2.1.csv", sep = ",")
res.pca <- PCA(df2[,-1], graph = F)

eig.val <- get_eigenvalue(res.pca)
eig.val
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 90))

var <- get_pca_var(res.pca)

corrplot(var$cos2, is.corr=FALSE)

fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE # Avoid text overlapping
)

fviz_pca_var(res.pca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)

fviz_pca_ind(res.pca,
             geom.ind = "point", # show points only (nbut not "text")
             col.ind =df2$tipo, # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups")
```
## 2.2 PCA base de datos PCA2
```{r, echo=TRUE,tidy=TRUE}
url<-"http://web.stanford.edu/~hastie/ElemStatLearn//datasets/zip.digits/train.2"
data<-read.csv(url)

data.pca = scale(data)
data.pca <- prcomp(data, center = F, scale=T)
prop_varianza <- data.pca$sdev^2 / sum(data.pca$sdev^2)
prop_varianza_acum <- cumsum(prop_varianza)

ggplot(data = data.frame(prop_varianza, pc = 1:256),
       aes(x = pc, y = prop_varianza)) +
  xlim(0, 50) +
  geom_col(width = 0.3) +
  scale_y_continuous(limits = c(0,.5)) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. de varianza explicada")

ggplot(data = data.frame(prop_varianza_acum, pc = 1:256),
       aes(x = pc, y = prop_varianza_acum, group = 1)) +
  geom_point() +
  geom_line() +
  geom_label(aes(label = round(prop_varianza_acum,2))) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. varianza explicada acumulada")
```

# 4. Metodo de reducción de dimensión (CCA)