<<<<<<< HEAD
---
title: "Examen Parcial 1"
author: "ByteMiners"
date: "23/02/2020"
output:
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Análisis exploratorio de datos
```{r, echo=TRUE,message=FALSE,warning=FALSE}
library(ggplot2)
library(cowplot)
library(dplyr)
library(grid)
library(FactoMineR)
library(factoextra)
library(corrplot)
```
# 1. Exploración y visualización de variables
## 1.1 Explorar la base de datos, realizar los cambios necesarios y convenientes para poder trabajar con ella.
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
df <- read.csv("Ejercicio 1.csv", sep = ",")

#Trasponer las columnas del df para que las características de cada observacion estén ordenadas por columnas 
df_transposed <- as.data.frame(t(as.matrix(df)))

# Eliminar observaciones con valores NA
df_transposed_omitted<-na.omit(df_transposed)

# Colocar nombre a las columnas y eliminar la primera fila 
names(df_transposed_omitted) <- c("Peso","Estatura","Edad","Complexión","Papas_separados","Cantidad_hermanos",
                                  "Trabaja", "Horas_trab_dia", "Horas_trab_mes", "Salario_mes")

updated_data <- df_transposed_omitted[-c(1),] 
```
## 1.2  Expliquen por medio de tablas esta información. En la tabla debe aparecer simultáneamente la frecuencia y el porcentaje
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
#Tabla de frecuencias de peso
frecuency_as_df<-as.data.frame(tabyl(updated_data$Peso, sort = TRUE))

names(frecuency_as_df) <- c("Peso","Frecuencia","Porcentaje")
final_weight_frecuency<-frecuency_as_df[-c(51),]

final_weight_frecuency

#Tabla de frecuencias de estatura
frecuency_as_df<-as.data.frame(tabyl(updated_data$Estatura, sort = TRUE))

names(frecuency_as_df) <- c("Estatura","Frecuencia","Porcentaje")
final_height_frecuency<-frecuency_as_df[-c(51),]

final_height_frecuency

#Tabla de frecuencias de edad
frecuency_as_df<-as.data.frame(tabyl(updated_data$Edad, sort = TRUE))

names(frecuency_as_df) <- c("Edad","Frecuencia","Porcentaje")
final_age_frecuency<-frecuency_as_df[-c(51),]

final_age_frecuency


#Tabla de frecuencias de complexion
frecuency_as_df<-as.data.frame(tabyl(updated_data$Complexión, sort = TRUE))

names(frecuency_as_df) <- c("Complexion","Frecuencia","Porcentaje")
final_constitution_frecuency<-frecuency_as_df[-c(1),]

final_constitution_frecuency


#Tabla de frecuencias de papás_separados
frecuency_as_df<-as.data.frame(tabyl(updated_data$Papás_separados, sort = TRUE))

names(frecuency_as_df) <- c("Papás_separados","Frecuencia","Porcentaje")
final_separated_parents_frecuency<-frecuency_as_df[-c(2),]

final_separated_parents_frecuency

#Tabla de frecuencias de cantidad_hermanos
frecuency_as_df<-as.data.frame(tabyl(updated_data$Cantidad_hermanos, sort = TRUE))

names(frecuency_as_df) <- c("Cantidad_hermanos","Frecuencia","Porcentaje")
final_number_of_brothers_frecuency<-frecuency_as_df[-c(7),]

final_number_of_brothers_frecuency

#Tabla de frecuencias de los que trabajan
frecuency_as_df<-as.data.frame(tabyl(updated_data$Trabaja, sort = TRUE))

names(frecuency_as_df) <- c("Trabaja","Frecuencia","Porcentaje")
final_iswork_frecuency<-frecuency_as_df[-c(3),]

final_iswork_frecuency

#Tabla de frecuencias de horas trabajadas x dia
frecuency_as_df<-as.data.frame(tabyl(updated_data$Horas_trab_dia, sort = TRUE))

names(frecuency_as_df) <- c("Horas_trabajo x dia","Frecuencia","Porcentaje")
final_worktime_per_day_frecuency<-frecuency_as_df[-c(8),]

final_worktime_per_day_frecuency

#Tabla de frecuencias de horas trabajadas por mes
frecuency_as_df<-as.data.frame(tabyl(updated_data$Horas_trab_mes, sort = TRUE))

names(frecuency_as_df) <- c("Horas_trabajo x mes","Frecuencia","Porcentaje")
final_worktime_per_month_frecuency<-frecuency_as_df[-c(10),]

final_worktime_per_month_frecuency

#Tabla de frecuencias de salarios mensuales
frecuency_as_df<-as.data.frame(tabyl(updated_data$Salario_mes, sort = TRUE))

names(frecuency_as_df) <- c("Salario x mes","Frecuencia","Porcentaje")
final_salary_per_month_frecuency<-frecuency_as_df[-c(24),]

final_salary_per_month_frecuency kk
```

##1.3 Hagan un gráfico donde pueda explicar las variables dependientes.
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
```

## 1.4 Construyan diferentes gráficos donde puedan mostrar patrones y detalles de la base de datos con respecto a una nueva variable que podemos denominar: “categoría”
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}

# Número de personas por categoría
cantidad_personas <- c(sum(with(updated_data, as.numeric(Edad) < 18.0)), 
                       sum(with(updated_data, as.numeric(Edad)>=18.0 & as.numeric(Edad)<=25.0)),
                       sum(with(updated_data, as.numeric(Edad) > 25.0)))

dist_personas <- data.frame(Categoria=c("Junior", "Señor", "Mayor"), Cantidad=cantidad_personas)
ggplot(dist_personas, aes(x=Categoria, y=Cantidad)) + geom_bar(stat = "identity") + coord_flip() + labs(title="Distribución de personas por categoría")+
  geom_text(aes(y=Cantidad, label=cantidad_personas), vjust=1.5, color="white", size=3.5, hjust="right")

# Salario mensual promedio de una persona dependiendo su categoría
junior <- filter(updated_data, as.numeric(Edad) <18.0)
senior <- filter(updated_data, as.numeric(Edad)>=18.0 & as.numeric(Edad)<=25.0)
mayor <- filter(updated_data, as.numeric(Edad) > 25.0)

prom_jun <- mean(as.numeric(as.numeric_version(junior$Salario_mes)))
prom_sen <- mean(as.numeric(as.numeric_version(senior$Salario_mes)))
prom_may <- mean(as.numeric(as.numeric_version(mayor$Salario_mes)))

Salario <- c(format(round(prom_jun, 2), nsmall = 2), 
                      format(round(prom_sen, 2), nsmall = 2),
                      format(round(prom_may, 2), nsmall = 2))

salario_trab <- data.frame(Categoria=c("Junior", "Señor", "Mayor"), Salario_Promedio = Salario)

ggplot(horas_trab, aes(x=Categoria, y=Salario)) + geom_bar(stat = "identity") + coord_flip() + labs(title="Salario mensual promedio dependiendo la categoría")+
  geom_text(aes(y=Salario, label=Salario), vjust=1.5, color="white", size=3.5, hjust="right")

# Número de personas con padres separados por categoría
cantidad_personas <- c(sum(with(junior, Papas_separados == "SI")), 
                       sum(with(senior, Papas_separados == "SI")),
                       sum(with(mayor, Papas_separados == "SI")))

dist_personas <- data.frame(Categoria=c("Junior", "Señor", "Mayor"), Cantidad=cantidad_personas)
ggplot(dist_personas, aes(x=Categoria, y=Cantidad)) + geom_bar(stat = "identity") + coord_flip() + labs(title="Número de personas con padres separados por categoría")+
  geom_text(aes(y=Cantidad, label=cantidad_personas), vjust=1.5, color="white", size=3.5, hjust="right")

```
# 2. Metodo de reducción de dimensión (PCA)


## 2.1 PCA base de datos PCA1
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
df2<-read.csv("Ejercicio 2.1.csv", sep = ",")
res.pca <- PCA(df2[,-1], graph = F)

eig.val <- get_eigenvalue(res.pca)
eig.val
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 90))

var <- get_pca_var(res.pca)

corrplot(var$cos2, is.corr=FALSE)

fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE # Avoid text overlapping
)

fviz_pca_var(res.pca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)

fviz_pca_ind(res.pca,
             geom.ind = "point", # show points only (nbut not "text")
             col.ind =df2$tipo, # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups")
```
## 2.2 PCA base de datos PCA2
```{r, echo=TRUE,tidy=TRUE}
url<-"http://web.stanford.edu/~hastie/ElemStatLearn//datasets/zip.digits/train.2"
data<-read.csv(url)

data.pca = scale(data)
data.pca <- prcomp(data, center = F, scale=T)
prop_varianza <- data.pca$sdev^2 / sum(data.pca$sdev^2)
prop_varianza_acum <- cumsum(prop_varianza)

ggplot(data = data.frame(prop_varianza, pc = 1:256),
       aes(x = pc, y = prop_varianza)) +
  xlim(0, 50) +
  geom_col(width = 0.3) +
  scale_y_continuous(limits = c(0,.5)) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. de varianza explicada")

ggplot(data = data.frame(prop_varianza_acum, pc = 1:256),
       aes(x = pc, y = prop_varianza_acum, group = 1)) +
  geom_point() +
  geom_line() +
  geom_label(aes(label = round(prop_varianza_acum,2))) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. varianza explicada acumulada")
```

=======
---
title: "Examen Parcial 1"
author: "ByteMiners"
date: "23/02/2020"
output:
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Análisis exploratorio de datos
```{r, echo=TRUE,message=FALSE,warning=FALSE}
library(ggplot2)
library(cowplot)
library(dplyr)
library(grid)
library(FactoMineR)
library(factoextra)
library(corrplot)
```
# 1. Exploración y visualización de variables
## 1.1 Explorar la base de datos, realizar los cambios necesarios y convenientes para poder trabajar con ella.
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
df <- read.csv("Ejercicio 1.csv", sep = ",")

#Trasponer las columnas del df para que las características de cada observacion estén ordenadas por columnas 
df_transposed <- as.data.frame(t(as.matrix(df)))

# Eliminar observaciones con valores NA
df_transposed_omitted<-na.omit(df_transposed)

# Colocar nombre a las columnas y eliminar la primera fila 
names(df_transposed_omitted) <- c("Peso","Estatura","Edad","Complexión","Papas_separados","Cantidad_hermanos",
                                  "Trabaja", "Horas_trab_dia", "Horas_trab_mes", "Salario_mes")

updated_data <- df_transposed_omitted[-c(1),] 
```
## 1.2  Expliquen por medio de tablas esta información. En la tabla debe aparecer simultáneamente la frecuencia y el porcentaje
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
```

##1.3 Hagan un gráfico donde pueda explicar las variables dependientes.
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
```

## 1.4 Construyan diferentes gráficos donde puedan mostrar patrones y detalles de la base de datos con respecto a una nueva variable que podemos denominar: “categoría”
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}

# Número de personas por categoría
cantidad_personas <- c(sum(with(updated_data, as.numeric(Edad) < 18.0)), 
                       sum(with(updated_data, as.numeric(Edad)>=18.0 & as.numeric(Edad)<=25.0)),
                       sum(with(updated_data, as.numeric(Edad) > 25.0)))

dist_personas <- data.frame(Categoria=c("Junior", "Señor", "Mayor"), Cantidad=cantidad_personas)
ggplot(dist_personas, aes(x=Categoria, y=Cantidad)) + geom_bar(stat = "identity") + coord_flip() + labs(title="Distribución de personas por categoría")+
  geom_text(aes(y=Cantidad, label=cantidad_personas), vjust=1.5, color="white", size=3.5, hjust="right")

# Salario mensual promedio de una persona dependiendo su categoría
junior <- filter(updated_data, as.numeric(Edad) <18.0)
senior <- filter(updated_data, as.numeric(Edad)>=18.0 & as.numeric(Edad)<=25.0)
mayor <- filter(updated_data, as.numeric(Edad) > 25.0)

prom_jun <- mean(as.numeric(as.numeric_version(junior$Salario_mes)))
prom_sen <- mean(as.numeric(as.numeric_version(senior$Salario_mes)))
prom_may <- mean(as.numeric(as.numeric_version(mayor$Salario_mes)))

Salario <- c(format(round(prom_jun, 2), nsmall = 2), 
                      format(round(prom_sen, 2), nsmall = 2),
                      format(round(prom_may, 2), nsmall = 2))

salario_trab <- data.frame(Categoria=c("Junior", "Señor", "Mayor"), Salario_Promedio = Salario)

ggplot(horas_trab, aes(x=Categoria, y=Salario)) + geom_bar(stat = "identity") + coord_flip() + 
  labs(title="Salario mensual promedio dependiendo la categoría")+
  geom_text(aes(y=Salario, label=Salario), vjust=1.5, color="white", size=3.5, hjust="right")

# Número de personas con padres separados por categoría
cantidad_personas <- c(sum(with(junior, Papas_separados == "SI")), 
                       sum(with(senior, Papas_separados == "SI")),
                       sum(with(mayor, Papas_separados == "SI")))

dist_personas <- data.frame(Categoria=c("Junior", "Señor", "Mayor"), Cantidad=cantidad_personas)
ggplot(dist_personas, aes(x=Categoria, y=Cantidad)) + geom_bar(stat = "identity") + coord_flip() + labs(title="Número de personas con padres separados por categoría")+
  geom_text(aes(y=Cantidad, label=cantidad_personas), vjust=1.5, color="white", size=3.5, hjust="right")

```
# 2. Metodo de reducción de dimensión (PCA)


## 2.1 PCA base de datos PCA1
```{r, echo=TRUE,warning=FALSE,tidy=TRUE}
df2<-read.csv("Ejercicio 2.1.csv", sep = ",")
res.pca <- PCA(df2[,-1], graph = F)

eig.val <- get_eigenvalue(res.pca)
eig.val
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 90))

var <- get_pca_var(res.pca)

corrplot(var$cos2, is.corr=FALSE)

fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE # Avoid text overlapping
)

fviz_pca_var(res.pca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)

fviz_pca_ind(res.pca,
             geom.ind = "point", # show points only (nbut not "text")
             col.ind =df2$tipo, # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups")
```
## 2.2 PCA base de datos PCA2
```{r, echo=TRUE,tidy=TRUE}
url<-"http://web.stanford.edu/~hastie/ElemStatLearn//datasets/zip.digits/train.2"
data<-read.csv(url)

data.pca = scale(data)
data.pca <- prcomp(data, center = F, scale=T)
prop_varianza <- data.pca$sdev^2 / sum(data.pca$sdev^2)
prop_varianza_acum <- cumsum(prop_varianza)

ggplot(data = data.frame(prop_varianza, pc = 1:256),
       aes(x = pc, y = prop_varianza)) +
  xlim(0, 50) +
  geom_col(width = 0.3) +
  scale_y_continuous(limits = c(0,.5)) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. de varianza explicada")

ggplot(data = data.frame(prop_varianza_acum, pc = 1:256),
       aes(x = pc, y = prop_varianza_acum, group = 1)) +
  geom_point() +
  geom_line() +
  geom_label(aes(label = round(prop_varianza_acum,2))) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. varianza explicada acumulada")
```

>>>>>>> 0bde6848c29aa78a5be9e6a031dbf4b7e81ff460
# 4. Metodo de reducción de dimensión (CCA)